{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "ka\n",
      "kha\n",
      "ga\n",
      "gha\n",
      "kna\n",
      "cha\n",
      "chha\n",
      "ja\n",
      "jha\n",
      "yna\n",
      "ta\n",
      "tha\n",
      "da\n",
      "dha\n",
      "ana\n",
      "taa\n",
      "thaa\n",
      "daa\n",
      "dhaa\n",
      "na\n",
      "pa\n",
      "pha\n",
      "ba\n",
      "bha\n",
      "ma\n",
      "ya\n",
      "ra\n",
      "la\n",
      "va\n",
      "motosaw\n",
      "petchiryosaw\n",
      "patalosaw\n",
      "ha\n",
      "ksha\n",
      "tra\n",
      "gya\n",
      "First test Dataset ready!\n",
      "a\n",
      "aa\n",
      "i\n",
      "ee\n",
      "u\n",
      "oo\n",
      "ae\n",
      "ai\n",
      "o\n",
      "au\n",
      "ka\n",
      "kha\n",
      "ga\n",
      "gha\n",
      "kna\n",
      "cha\n",
      "chha\n",
      "ja\n",
      "jha\n",
      "yna\n",
      "ta\n",
      "tha\n",
      "da\n",
      "dha\n",
      "ana\n",
      "taa\n",
      "thaa\n",
      "daa\n",
      "dhaa\n",
      "na\n",
      "pa\n",
      "pha\n",
      "ba\n",
      "bha\n",
      "ma\n",
      "ya\n",
      "ra\n",
      "la\n",
      "va\n",
      "motosaw\n",
      "petchiryosaw\n",
      "patalosaw\n",
      "ha\n",
      "ksha\n",
      "tra\n",
      "gya\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Train Dataset Ready!\n",
      "ka\n",
      "kha\n",
      "ga\n",
      "gha\n",
      "kna\n",
      "cha\n",
      "chha\n",
      "ja\n",
      "jha\n",
      "yna\n",
      "ta\n",
      "tha\n",
      "da\n",
      "dha\n",
      "ana\n",
      "taa\n",
      "thaa\n",
      "daa\n",
      "dhaa\n",
      "na\n",
      "pa\n",
      "pha\n",
      "ba\n",
      "bha\n",
      "ma\n",
      "ya\n",
      "ra\n",
      "la\n",
      "va\n",
      "motosaw\n",
      "petchiryosaw\n",
      "patalosaw\n",
      "ha\n",
      "ksha\n",
      "tra\n",
      "gya\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Test Dataset Ready!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def writefile(data,path):\n",
    "    df=pd.DataFrame(np.array(data,dtype=\"object\"))\n",
    "    with open(path,'a+') as f:\n",
    "        df.to_csv(f,mode='a',header=False)\n",
    "\n",
    "def load_images_from_folder(folder,letter,output):\n",
    "    # flag=0\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        final=[]\n",
    "        img = cv2.imread(os.path.join(folder,filename),0)\n",
    "        img=255-img\n",
    "        roi=img[2:30,2:30]\n",
    "        final.append([str(letter)]+list(roi.flatten()))\n",
    "        writefile(final,output)\n",
    "        # if flag==0:\n",
    "        #     cv2.imshow('image',img)\n",
    "        #     cv2.imshow('cropped',roi)\n",
    "        #     print(img.shape)\n",
    "        #     print(roi.shape)\n",
    "        #     cv2.waitKey(0)\n",
    "        #     cv2.destroyAllWindows()\n",
    "        #     flag=1\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "# path='dataset/Train/digit_'\n",
    "# for i in range(0,10):\n",
    "#     load_images_from_folder(path+str(i),str(i),'dataset.csv')    \n",
    "#     print(i)\n",
    "\n",
    "def load_images_from_folder_2(folder,letter,output):\n",
    "    # flag=0\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        final=[]\n",
    "        img = cv2.imread(os.path.join(folder,filename),0)\n",
    "        final.append([str(letter)]+list(img.flatten()))\n",
    "        writefile(final,output)\n",
    "        # if flag==0:\n",
    "        #     cv2.imshow('image',img)\n",
    "        #     cv2.imshow('cropped',roi)\n",
    "        #     print(img.shape)\n",
    "        #     print(roi.shape)\n",
    "        #     cv2.waitKey(0)\n",
    "        #     cv2.destroyAllWindows()\n",
    "        #     flag=1\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "path='nhcd/numerals/'\n",
    "for i in range(0,10):\n",
    "        load_images_from_folder_2(path+str(i),str(i),'dataset.csv')\n",
    "        print(i)\n",
    "consonants=['ka','kha','ga','gha','kna','cha','chha','ja','jha','yna','ta','tha','da','dha','ana','taa','thaa','daa','dhaa','na','pa','pha','ba','bha','ma','ya','ra','la','va','motosaw','petchiryosaw','patalosaw','ha','ksha','tra','gya']\n",
    "path='nhcd/consonants/'\n",
    "for i in range(0,36):\n",
    "        load_images_from_folder_2(path+str(i+1),consonants[i],'dataset.csv')\n",
    "        print(consonants[i])\n",
    "print(\"First test Dataset ready!\")\n",
    "\n",
    "path='nhcd/vowels/'\n",
    "vowels=['a','aa','i','ee','u','oo','ae','ai','o','au','an','ah']\n",
    "for i in range(0,10):\n",
    "        load_images_from_folder_2(path+str(i+1),vowels[i],'train.csv')\n",
    "        print(vowels[i])\n",
    "hindi_letters=['ka','kha','ga','gha','kna','cha','chha','ja','jha','yna','ta','tha','da','dha','ana','taa','thaa','daa','dhaa','na','pa','pha','ba','bha','ma','ya','ra','la','va','motosaw','petchiryosaw','patalosaw','ha','ksha','tra','gya']\n",
    "path='dataset/Train/character_'\n",
    "for i in range(0,36):\n",
    "    load_images_from_folder(path+str(i+1),hindi_letters[i],'train.csv')    \n",
    "    print(hindi_letters[i])\n",
    "path='dataset/Train/digit_'\n",
    "for i in range(0,10):\n",
    "    load_images_from_folder(path+str(i),str(i),'train.csv')    \n",
    "    print(i)\n",
    "print(\"Train Dataset Ready!\")\n",
    "\n",
    "path='dataset/Test/character_'\n",
    "for i in range(0,36):\n",
    "    load_images_from_folder(path+str(i+1),consonants[i],'test.csv')    \n",
    "    print(consonants[i])\n",
    "path='dataset/Test/digit_'\n",
    "for i in range(0,10):\n",
    "\n",
    "    load_images_from_folder(path+str(i),str(i),'test.csv')    \n",
    "    print(i)\n",
    "print(\"Test Dataset Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
